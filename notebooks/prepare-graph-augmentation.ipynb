{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "import dgl.nn as nn\n",
    "import dgl.function as fn\n",
    "import dgl.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_config(data, config_path):\n",
    "    with open(config_path, 'w') as f:\n",
    "        data = yaml.dump(data, f)\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Graph Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* node degree\n",
    "* numerical feature aggregation (average, max, min)\n",
    "* categorical features aggregation (category ratios over neighbours)\n",
    "* binary features aggregation (ratios over neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.ndata['features'] = torch.tensor(num_features)\n",
    "# graph.update_all(fn.copy_u('features', 'message'), fn.sum('message', 'features_sum'))\n",
    "\n",
    "def get_structural_features(graph):\n",
    "    structural_features = graph.in_degrees().numpy().astype(np.float32).reshape(-1, 1)\n",
    "    structural_feature_names = ['node_degree']\n",
    "\n",
    "    return structural_features, structural_feature_names\n",
    "\n",
    "\n",
    "def get_num_feature_aggregation(graph, features, feature_names):\n",
    "    aggregation_types = ['mean', 'max', 'min']\n",
    "\n",
    "    with graph.local_scope():\n",
    "        graph.ndata['f'] = torch.FloatTensor(features)\n",
    "        aggregated_features_container = []\n",
    "\n",
    "        for aggregation_type in aggregation_types:\n",
    "            graph.update_all(fn.copy_u('f', 'm'), getattr(fn, aggregation_type)('m', aggregation_type))\n",
    "            aggregated_features_container.append(graph.ndata[aggregation_type])\n",
    "\n",
    "        aggregated_features = torch.cat(aggregated_features_container, dim=1).numpy().astype(np.float32)\n",
    "        aggregated_features_names = [\n",
    "            f\"{feature_name}_{aggregation_type}\" \n",
    "            for aggregation_type in aggregation_types for feature_name in feature_names\n",
    "        ]\n",
    "    \n",
    "    return aggregated_features, aggregated_features_names\n",
    "\n",
    "\n",
    "def get_cat_feature_aggregation(graph, features, feature_names):\n",
    "    df_features = pd.DataFrame(features, columns=feature_names).astype(np.int32)\n",
    "    df_ohe = pd.get_dummies(df_features, columns=feature_names, sparse=False, drop_first=False)\n",
    "    ohe_features = df_ohe.values\n",
    "    ohe_feature_names = df_ohe.columns\n",
    "\n",
    "    with graph.local_scope():\n",
    "        graph.ndata['f'] = torch.FloatTensor(ohe_features)\n",
    "        graph.update_all(fn.copy_u('f', 'm'), fn.mean('m', 'mean'))\n",
    "        \n",
    "        aggregated_features = graph.ndata['mean'].numpy().astype(np.float32)\n",
    "        aggregated_features_names = [f\"{feature_name}_mean\" for feature_name in ohe_feature_names]\n",
    "    \n",
    "    return aggregated_features, aggregated_features_names\n",
    "    \n",
    "\n",
    "def get_bin_feature_aggregation(graph, features, feature_names):\n",
    "    with graph.local_scope():\n",
    "        graph.ndata['f'] = torch.FloatTensor(features)\n",
    "        graph.update_all(fn.copy_u('f', 'm'), fn.mean('m', 'mean'))\n",
    "        \n",
    "        aggregated_features = graph.ndata['mean'].numpy().astype(np.float32)\n",
    "        aggregated_features_names = [f\"{feature_name}_mean\" for feature_name in feature_names]\n",
    "    \n",
    "    return aggregated_features, aggregated_features_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Graph Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    # 'tolokers-tab',\n",
    "    # 'questions-tab',\n",
    "    # 'city-reviews',\n",
    "    # 'browser-games',\n",
    "    # 'hm-categories',\n",
    "    # 'web-fraud',\n",
    "    # 'city-roads-M',\n",
    "    # 'city-roads-L',\n",
    "    # 'avazu-devices',\n",
    "    # 'hm-prices',\n",
    "    # 'web-traffic'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(dataset_name)\n",
    "    dataset_path = f\"{data_root}/{dataset_name}\"\n",
    "\n",
    "    df_features = pd.read_csv(f'{dataset_path}/features.csv', index_col=0)\n",
    "    dataset_info = load_config(f'{dataset_path}/info.yaml')\n",
    "\n",
    "    edge_list = pd.read_csv(f\"{dataset_path}/edgelist.csv\").values[:, :2]\n",
    "    graph = dgl.graph(tuple(torch.tensor(indices) for indices in edge_list.T))\n",
    "    graph = dgl.to_bidirected(graph)\n",
    "    graph = dgl.add_self_loop(graph)\n",
    "\n",
    "    structural_features, structural_feature_names = get_structural_features(graph)\n",
    "    augmented_features_container = [structural_features]\n",
    "    augmented_feature_names_container = [structural_feature_names]\n",
    "    \n",
    "    if dataset_info['num_feature_names']:\n",
    "        num_feature_names = dataset_info['num_feature_names']\n",
    "        num_features = df_features[num_feature_names].values\n",
    "        aggregated_num_features, aggregated_num_features_names = get_num_feature_aggregation(graph, num_features, num_feature_names)\n",
    "        \n",
    "        augmented_features_container.append(aggregated_num_features)\n",
    "        augmented_feature_names_container.append(aggregated_num_features_names)\n",
    "    else:\n",
    "        aggregated_num_features_names = []\n",
    "\n",
    "    if dataset_info['cat_feature_names']:\n",
    "        cat_feature_names = dataset_info['cat_feature_names']\n",
    "        cat_features = df_features[cat_feature_names].values\n",
    "        aggregated_cat_features, aggregated_cat_features_names = get_cat_feature_aggregation(graph, cat_features, cat_feature_names)\n",
    "\n",
    "        augmented_features_container.append(aggregated_cat_features)\n",
    "        augmented_feature_names_container.append(aggregated_cat_features_names)\n",
    "    else:\n",
    "        aggregated_cat_features_names = []\n",
    "\n",
    "    if dataset_info['bin_feature_names']:\n",
    "        bin_feature_names = dataset_info['bin_feature_names']\n",
    "        bin_features = df_features[bin_feature_names].values\n",
    "        aggregated_bin_features, aggregated_bin_features_names = get_bin_feature_aggregation(graph, bin_features, bin_feature_names)\n",
    "\n",
    "        augmented_features_container.append(aggregated_bin_features)\n",
    "        augmented_feature_names_container.append(aggregated_bin_features_names)\n",
    "    else:\n",
    "        aggregated_bin_features_names = []\n",
    "\n",
    "    augmented_info = {\n",
    "        'structural_feature_names': structural_feature_names,\n",
    "        'aggregated_num_feature_names': aggregated_num_features_names,\n",
    "        'aggregated_cat_feature_names': aggregated_cat_features_names,\n",
    "        'aggregated_bin_feature_names': aggregated_bin_features_names,\n",
    "    }\n",
    "\n",
    "    augmented_features = np.concatenate(augmented_features_container, axis=1)\n",
    "    augmented_feature_names = np.concatenate(augmented_feature_names_container, axis=0)\n",
    "    \n",
    "    augmented_features_path = f'{dataset_path}/augmented_features.csv'\n",
    "    df_augmented_features = pd.DataFrame(augmented_features, columns=augmented_feature_names)\n",
    "    df_augmented_features.to_csv(augmented_features_path)\n",
    "\n",
    "    augmented_info_path = f'{dataset_path}/augmented_info.yaml'\n",
    "    save_config(augmented_info, augmented_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
